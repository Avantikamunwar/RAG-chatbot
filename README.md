AI Chatbot using Retrieval-Augmented Generation (RAG)

A production-ready AI Chatbot built using FastAPI, Pinecone vector database, Ollama embeddings, and LLM-based context-aware answering.
This project demonstrates how to build an end-to-end Retrieval-Augmented Generation system that can intelligently answer user queries based only on your documents.

 Project Overview

This chatbot combines vector embeddings, semantic search, and LLM reasoning to deliver accurate, document-grounded responses.

 Key Capabilities

 Automatic document ingestion (PDF/TXT)

 Smart text chunking for high-quality retrieval

 Embeddings generation using Ollama

 Semantic search via Pinecone

 Context-aware responses using RAG

 FastAPI backend with REST APIs

 CORS enabled for frontend integration

 Clean code and modular architecture
